# -*- coding: utf-8 -*-
"""cod de redes neu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16o7dukcVdfNOZivdJqSkb08sZZlNaFig
"""

#importar librerias
import tensorflow as tf #biblioteca construir y entrenar modelos de ap profundo
from tensorflow.keras.models import Sequential #sequential construye modelos capa a capa
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout #capas de redes convulacionales
from tensorflow.keras.datasets import mnist #es una base de datos de dignitos manuescritos
import matplotlib.pyplot as plt

#conjunto de datos
(x_train, y_train), (x_test, y_test) = mnist.load_data()#x tendra las imagenes y Y tendra las etiquetas

#normalizar los datos
x_train = x_train.reshape(-1,28,28,1).astype('float32')/255.0
x_test = x_test.reshape(-1,28,28,1).astype('float32')/255.0

#codificar las eiquetas
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test,10)

plt.figure(figsize=(10,5))
for i in range(6):
    plt.subplot(2,3,i+1)
    plt.imshow(x_train[i].reshape(28,28), cmap='gray')
    plt.title(f"Etiqueta: {y_train[i].argmax()}")
    plt.axis('off')
    plt.show()

model=Sequential([
    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D(pool_size=(2,2)),
    Dropout(0,25),

    #segunda capa convulacional
    Conv2D(64, kernel_size=(3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),
    Dropout(0,25),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

#compilar el modelo
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

#entrenamiento
history = model.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.2)

#evaluar el desempeño
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Exactitud en el conjunto de prueba: {test_acc:0.4f}")

#graficar  acc y la prueba
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label="Exactitud en el entrenamiento")
plt.plot(history.history['val_accuracy'], label="Exactitud en la validaciòn")
plt.xlabel('Épocas')
plt.ylabel('Exactitud')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="Perdida en el entrenamiento")
plt.plot(history.history["val_loss"], label="Perdida en la validaciòn")
plt.xlabel('Épocas')
plt.ylabel('Perdida')
plt.legend()
plt.show()

#predicciones para test
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
import seaborn as sns
y_pred_probs=model.predict(x_test)
y_pred=np.argmax(y_pred_probs, axis=1) #etiquetas predichas
y_true=np.argmax(y_test, axis=1) #etiqiuetas reales

#matriz de confusion

conf_matrix=confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))
plt.title('Matriz de Confusión')
plt.xlabel('Predicciones')
plt.ylabel('Etiquetas Reales')
plt.show()

fpr={}
tpr={}
roc_auc={}
n_classes=10
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

#calcular el auc
plt.figure(figsize=(8,6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label=f'Clase {i} (AUC = {roc_auc[i]:.2f})')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC')
plt.legend()
plt.show()

#reporet de clasificacion
print("Reporte de clasificacion")
print(classification_report(y_true, y_pred))